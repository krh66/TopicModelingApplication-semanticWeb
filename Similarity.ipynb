{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\q4116\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\q4116\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "  >>> import nltk\n",
    "  >>> nltk.download('punkt')\n",
    "  >>> nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      While answering a few of EdChum's questions I ...\n",
      "1      Being newly created we have zero feeds appeari...\n",
      "2      It looks like filter coffee has another, diffe...\n",
      "3      The chatroom name is so bland. \"Coffee.\" Look ...\n",
      "4      On most SE sites, product recommendations are ...\n",
      "                             ...                        \n",
      "229    Indicates that the post shares product or conf...\n",
      "230    Seasoned Advice has excluded recipe requests f...\n",
      "231    I appreciate the Seasoned Advice stance and th...\n",
      "232                                                  NaN\n",
      "233                                                  NaN\n",
      "Name: Body, Length: 234, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/dataset.csv\", encoding=\"utf_8\")\n",
    "print(data[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Being newly created we have zero feeds appearing in our main chat right now. What blogs, news sites, or other important coffee related things should appear in our main chat room's feed? Post your suggestions/submissions.  \\n\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Body\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def removeStopWords(words):\n",
    "    res = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            res.append(word)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Being',\n",
       " 'newly',\n",
       " 'created',\n",
       " 'zero',\n",
       " 'feeds',\n",
       " 'appearing',\n",
       " 'main',\n",
       " 'chat',\n",
       " 'right',\n",
       " 'What',\n",
       " 'blogs',\n",
       " 'news',\n",
       " 'sites',\n",
       " 'important',\n",
       " 'coffee',\n",
       " 'related',\n",
       " 'things',\n",
       " 'appear',\n",
       " 'main',\n",
       " 'chat',\n",
       " 'room',\n",
       " 'feed',\n",
       " 'Post',\n",
       " 'suggestions',\n",
       " 'submissions']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeStopWords(tokenizer.tokenize(data[\"Body\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "tfidf = TfidfVectorizer().fit_transform(data[\"Body\"].values.astype('U'))\n",
    "pairwise_similarity = tfidf * tfidf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<234x3227 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15170 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.05440365, 0.23681405, ..., 0.17617061, 0.        ,\n",
       "        0.        ],\n",
       "       [0.05440365, 1.        , 0.01062189, ..., 0.05763601, 0.        ,\n",
       "        0.        ],\n",
       "       [0.23681405, 0.01062189, 1.        , ..., 0.06332468, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.17617061, 0.05763601, 0.06332468, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = pairwise_similarity.toarray()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       nan, 0.05440365, 0.23681405, ..., 0.17617061, 0.        ,\n",
       "        0.        ],\n",
       "       [0.05440365,        nan, 0.01062189, ..., 0.05763601, 0.        ,\n",
       "        0.        ],\n",
       "       [0.23681405, 0.01062189,        nan, ..., 0.06332468, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.17617061, 0.05763601, 0.06332468, ...,        nan, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        ,        nan,\n",
       "        1.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "               nan]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fill_diagonal(arr, np.nan)\n",
    "input_idx = 2\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chatroom name is so bland. \"Coffee.\" Look at all the creative names others have thought up:\n",
      "\n",
      "\"Root Access\" for Super User\n",
      "\"The DMZ\" for Security\n",
      "\"The Renderfarm\" for Blender\n",
      "\"The Litter Box\" for Pets\n",
      "\"The Hangar\" for Aviation\n",
      "\"You Are Here\" for Travel\n",
      "\"The Water Cooler\" for The Workplace\n",
      "\"The Whiteboard\" for Programmers\n",
      "\"The Nineteenth Byte\" for Code Golf\n",
      "etc...\n",
      "\n",
      "Can we think of a better name for our chatroom?\n",
      "Only one idea per answer, please. Vote up the ideas that you like!\n",
      "Stolen from Lifehacks meta, which was in turn stolen from PPCG meta. But that's okay, because I wrote both of those posts too. :P\n",
      "\n",
      "-----------------------------------------------\n",
      "\"Stackbucks Coffee\"\n",
      "Sorry, that was too tempting... I like the chatty aspect, though.\n",
      "\n",
      "0.3077635065405421\n"
     ]
    }
   ],
   "source": [
    "result_idx = np.nanargmax(arr[input_idx])\n",
    "\n",
    "print(data[\"Body\"][input_idx+1])\n",
    "print(\"-----------------------------------------------\")\n",
    "print(data[\"Body\"][result_idx+1])\n",
    "print(arr[input_idx][result_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([233,  59,  37, 201, 100, 108, 232, 169, 219, 216, 184,  93,  23,\n",
       "       112,   1,  27, 183, 153, 194, 193,  75, 188,  12, 209,   4,  86,\n",
       "         6, 217,  31, 212, 165,  47,   9, 177, 189, 160,  38, 123,  60,\n",
       "        51, 170,  84, 159, 229, 132,  26,  82,  66, 178,  63, 142,  92,\n",
       "        36,  88, 208, 128, 130,  40, 207, 138,  42, 213, 161,  28,  57,\n",
       "       151, 190,  64,  32,  56, 202, 200, 133,  15, 158, 221,  89,  91,\n",
       "        24, 171,  90,  33, 225, 182, 168,  99, 205, 109, 179, 186, 210,\n",
       "        53, 192,  65, 187,  11,  25,  61,  46,  19, 198,  85, 111, 222,\n",
       "       176, 228,  55, 211, 113,  79,  50,   7,  69, 122,  13, 141, 167,\n",
       "        95,  10, 206, 155,  29, 174, 231, 131, 115, 223, 110, 203, 226,\n",
       "        68, 215, 195,  73, 180, 230, 106, 105, 135, 144, 162, 119,  41,\n",
       "        34,  16, 116,  96,  14,   8,  20, 164,  62, 173,  39,  97, 120,\n",
       "        94, 154, 218, 199,  49,  98, 227, 156, 204,  72,  81, 127,  18,\n",
       "        30, 125, 163,  22,  52, 166, 129,  83, 139,  45, 124, 137, 117,\n",
       "       181,  58, 152, 224, 143, 175, 134,  80, 214,  44, 191, 104, 197,\n",
       "        77,  78,  74, 220,  54, 103, 157,  35, 136, 114, 102,  67, 146,\n",
       "        87,   3, 145,   5, 185, 150, 196, 147, 101,  48, 149,  71,  43,\n",
       "       121, 107,  17, 118, 126, 172, 148, 140,  76,  70,   0,  21,   2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(arr[input_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
