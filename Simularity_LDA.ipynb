{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = None\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(pd.read_csv(\"./data/dataset.csv\", encoding=\"utf_8\")[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "#                                    max_features=n_features,\n",
    "#                                    stop_words='english')\n",
    "# tfidf = tfidf_vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf = NMF(n_components=n_components, random_state=1,\n",
    "#           alpha=.1, l1_ratio=.5).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "# print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmf = NMF(n_components=n_components, random_state=1,\n",
    "#           beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "#           l1_ratio=.5).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "# print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b69c09cd8c5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\PY37\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \"\"\"\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m         X = self._check_non_neg_array(X, reset_n_features=True,\n\u001b[0;32m    557\u001b[0m                                       whom=\"LatentDirichletAllocation.fit\")\n",
      "\u001b[1;32mD:\\Softwares\\Anaconda3\\envs\\PY37\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;34m\"\"\"Check model parameters.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             raise ValueError(\"Invalid 'n_components' parameter: %r\"\n\u001b[0;32m    315\u001b[0m                              % self.n_components)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_var_ratios = lda.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function\n",
    "select_n_components(lda_var_ratios, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: coffee don flavor think tags questions topic want sites meta flavored hold little duplicate suggestions good needs just answers different\n",
      "Topic #1: run reputation coffeemaker species site sa variation decide recommendations size proposals award improve removed beverage users including project excellent hoc_age\n",
      "Topic #2: questions question site explanations ingredients stackexchange key possibly did matter merged happen app drug soon situation yes unless existing thinking\n",
      "Topic #3: products uk just term japan drip spurred case future color main light communities edited refers kinds amortize coffee use links\n",
      "Topic #4: topic question product apply bean expect opinion long answers recommendations answer specific bad se interface recommendation disclaimer storage flagged wait\n",
      "Topic #5: differences growing zero line question coffee written worded does related criteria closed drug didn extent maintain suggested wikis list subject\n",
      "Topic #6: site work given welcome time just rest search ve likely answer really grown sorts days regional warm bit mods 24\n",
      "Topic #7: drip coffee consuming unaccepted summary old sweet worth edits tag earning original talking feature brewing website bounty initial traditional moment\n",
      "Topic #8: image area51 ads proposal png ad stackexchange generic 150 simple create space good size standard proposals pretty requirements sites fully\n",
      "Topic #9: confused like result migrate synonyms sweet started flavor favor certain moving unaccepted filter line discussions short dropdown interesting dr 13\n",
      "Topic #10: rep queue user edit users situation posts necessary meta sites custom thing general flags tasks activity year threshold moderation regular\n",
      "Topic #11: question bit context author likely rest guidance answered decide fundamentally leave posting aside sorry methods suspended² considered big deal end\n",
      "Topic #12: acceptable coffee tired event feel generally guidelines self promotion http going like don yes mod glass large long learning answers\n",
      "Topic #13: badge professionals hits ambiguous en canonical gave draw say proposed possible yes aspects policy left blog guidance try earning products\n",
      "Topic #14: question com mod different case standard searched yesterday starting descaler asked prior focus product generic december features pour despite explanations\n",
      "Topic #15: members community moderators learning challenges issues time job moderator site building exactly select welcoming 2015 wish failure excellent yes help\n",
      "Topic #16: voting searched original totally 90 process sorts future easier types png tired minimum interface terms closed serving disagree speculation rule\n",
      "Topic #17: ground created assume goes direct putting describing places automatically software differ sage 150 completely discussion avatar best couple ambiguous possibly\n",
      "Topic #18: product provide page asker sense se disclaimer line policy recommendations beans valid link 13 handled months warrant kopi didn self\n",
      "Topic #19: roast flavor wishing understanding opinions drop fewer field tend wasn don whited thinking daily tour caffeine hope game fun bitter\n",
      "Topic #20: coffeemaker adding way broad includes said ad possible fundamental free effort project area people changed menu works actually suggestion discovery\n",
      "Topic #21: questions close sorry private belong quickly bounty did guys let wish means rest site nearly edit regarding value internet ve\n",
      "Topic #22: bounty answer period award half voted rep ending hours value 24 didn provided 75 start reputation automatically posted question did\n",
      "Topic #23: tag wiki flavor edit content brewing process suggested like history suggest summary wikis edited temperature approved did looks bean taste\n",
      "Topic #24: water percolator grounds moka brewed separate coffee beginning stovetop storage espresso brew terminology goes think ambiguous remain different grind drop\n",
      "Topic #25: logo cup seasoned disagree correct discovery policy value quickly circumstances written award course known worked reason members space spent problematic\n",
      "Topic #26: moderator particular summary filter wishing free sweet putting examples ingredient posted answerable draw cup handle mod overflow suspended² post plain\n",
      "Topic #27: community questions user method process short thought time types meta question length suppose world great value future doesn regarding topics\n",
      "Topic #28: questions summary meta seasoned deserves research kind list asking duplicate blog week drinker learning easy directly refer search based interested\n",
      "Topic #29: coffee stack project exchange topic site text answer tea question disagree allow mark need walled questions sites tell good recreated\n",
      "Topic #30: break goes discussing london chat vote café refers appear seen voted special comments weird products big resource summary highest concept\n",
      "Topic #31: question questions works sounds coffee key answer hope types reviewing descaler feeds systems writing short type interested received stackexchange soon\n",
      "Topic #32: cups appreciate allow indicate clarification did aside thoughts apparently finding blog solid minimum gear major proposals sure break different fits\n",
      "Topic #33: day site good spend like pour misleading beta area51 wonder year means think features migration terminology questions need money spent\n",
      "Topic #34: need downvoted completely canonical wide reputation used experts views 12 edited automated remain belong grind drug unique takes dropdown adding\n",
      "Topic #35: numerous fortunately public quickly misleading look clarification flag cups yesterday intended water far appropriate related frame café gaggia button potential\n",
      "Topic #36: quite posts view mention accomplish sure reasons wanted synonym information famous maintain diamond feedback make critical flavoring turn london 2015\n",
      "Topic #37: grind grinding beans ground disclaimer grounds process grinds certain say past espresso method product result refer appropriate coffee london situation\n",
      "Topic #38: press caffeine data store stuff consider came zero questions moment self moderators immediately thought drinkers thinking wishing fewer 75 covered\n",
      "Topic #39: know does clarification wishing message recipes fundamental en opinions obvious tastes learned issues beta advice make spammers hats mention away\n",
      "Topic #40: spam posts question answer coffee include flagged line specific website product considered hopefully comments solutions company user issue post support\n",
      "Topic #41: questions background author considered issue topic bitter based edit true recommended didn voting feed primarily migrated ones arabica follow goal\n",
      "Topic #42: cooking coffee questions site answer answers make question flag migrated like just asking advice product experts think possible seasoned expertise\n",
      "Topic #43: taste en engine need form descaling best variations looks deleted subjective describing little moving possible drinking flavour suggest walled tags\n",
      "Topic #44: room changing sorry game producing hand affect bit custom question barista bad math appear requests allow makes coffee subjective maybe\n",
      "Topic #45: grounds spent grinds left cases refer grinder seen make correct person comes roasting suggestion brewing enjoy look sure spirit people\n",
      "Topic #46: flavor brewing process tag summary gateway ad drink approved member coffees beverages limit hot special polls ll haven covered famous\n",
      "Topic #47: survive shop december easy old food context obviously flavoring forth primary moderator allow bounty place forever highly distinguishing job common\n",
      "Topic #48: com follows dozens true https virtue user dropdown chat major wrong health needs recently obvious clear asker drink traffic hope\n",
      "Topic #49: filter skip strikes systems background possibly 12 point uk duplicates maintain misleading initial need press points awesome user primary types\n",
      "Topic #50: effort require lot asker google glad dr asking experiences written sources solve exchange means wiki far prior convention extent stop\n",
      "Topic #51: questions coffee author users success position application building sites quickly using major prior short site does zero attract finally posts\n",
      "Topic #52: coffee tea oil beta does steam space roast stovetop circumstances takes true terms exact sure 12 obvious professionals beverages refers\n",
      "Topic #53: tags kopi product skip feedback asking allow did ingredients personal se fits health view topic post coffee called checked virtue\n",
      "Topic #54: gets searching think synonyms chatroom logo merged threshold meaningful lead fun hope favor confused potentially answer expand gateway caffeine unique\n",
      "Topic #55: caffeine place se sure questions way question coffee right tea health better area happen png answer hats discuss logo asking\n",
      "Topic #56: favorite roasting improve describing little called original common upvote direction starting bitter chat reviews discuss home details way automated result\n",
      "Topic #57: diamond tag started feel ambiguous welcome moderator quite unique currently likely coming downvote forth couple deserts word reason considered dark\n",
      "Topic #58: tag wiki just think known merged drinker www luwak iced issues submitted problematic doing left worth does ambiguous say defined\n",
      "Topic #59: post contributions currently community product goal generic appreciated feedback applies activity ago tag fundamental includes specific work moderators questions add\n",
      "Topic #60: thing make known suggest scientific questions exact different action certain potentially verifiable weird convention spent room space future contributed value\n",
      "Topic #61: guys community custom level tried apparently somewhat general preparation avatar going mind discovery area lead member directly potentially wouldn product\n",
      "Topic #62: area 51 proposal beverages tea coffee ask said topic related ve health gets links excellent different numbers 10 taste initial\n",
      "Topic #63: research don legitimate think fact opinion answers high original coffee quality facts backed topic misleading added doesn references 75 site\n",
      "Topic #64: recreated identify processed privileges standard december answered quite tagged migrated flag potentially queue tiny comments source properly developing efforts requests\n",
      "Topic #65: coffee se knowledge don think sense topic know good sound real problem wikis types nature sources recommendations identify chat arabica\n",
      "Topic #66: recommendations needed text descaler weeks solutions forever hard internet reviews names legitimate drop area continue submit based kind previous stovetop\n",
      "Topic #67: question descaler asking answers answer flavor ask questions descaling sage like meta subjective coffee gaggia just stack having searched people\n",
      "Topic #68: coffee tag tags weird based moderator reason perfectly basic meta drinking accomplished provide mods field neatly turn verification providing comments\n",
      "Topic #69: wait issue flags using network identify affect kind upvote 13 interested ones reviewing iced goal similar 2015 understanding 12 case\n",
      "Topic #70: coffee topic question questions opinion based broad site advice seasoned know beans answer bean se think probably people answers example\n",
      "Topic #71: expedient matter efforts features change expertise grinds skip said thread store worded solved famous hot cooking japan type moving allow\n",
      "Topic #72: coffee question does luwak let somewhat taste posts totally similar kopi beans think convention ad linked 75 unless tried example\n",
      "Topic #73: think recipes lot interesting recommended suspended api lead recreated prior opinion frequency examples winter certainly improve editing confused suggests taste\n",
      "Topic #74: coffee question questions site answer like think answers just community se don new people sites users meta stack good tag\n",
      "Topic #75: fun various year write set special flagged changed secret rooms encourage support consider hopefully disagree general polls footnotes starting reasons\n",
      "Topic #76: support brew points aspects explanations drug synonym determine accepted handle directly coffeemaker data count original warm basically coffee changing ll\n",
      "Topic #77: community week suggest stuff users use according people google trends share moka tag ve especially context idea money significant isn\n",
      "Topic #78: having suppose beverage really 75 steam contributions position types discourage potentially format rep tried experts png solved follows tastes known\n",
      "Topic #79: beta ideas public like stack 2015 stuff sites coffee icons slightly exchange private subject start shown relevant moment appreciated polls\n",
      "Topic #80: flags flavoring won happy london wouldn breville active biology thing zero dark folks shouldn variations button big numerous french members\n",
      "Topic #81: questions answer question wikipedia answers opinion sources don wiki quite coffee famous community related original accepting approach late open site\n",
      "Topic #82: lot coffee edits stack accepted ads sites exchange need feature exactly basically intended visit point meta synonym edit good actions\n",
      "Topic #83: coffee se main tea espresso 51 finally sites examples software café press pour important new special shape day zero late\n",
      "Topic #84: minimum removed application continue feed discouraged words icons ve hard exact difference approved london hits distinguishing previously policy add drinkers\n",
      "Topic #85: code idea thought reputation ve hand chatroom ideas like topics meta sage appear working png end suggestion vigilant tasks 90\n",
      "Topic #86: coffee tag method edited pour drip brewing use fine shown think half process terms different hope having signatures removed expert\n",
      "Topic #87: 10 extent intended place decide search bit little happen obvious add suspend meaningful tired submit far ago suggestions actions assume\n",
      "Topic #88: famous café late quite percolator challenges redundant matter says wikipedia created thing relevant differ pop tastes getting suspect tag try\n",
      "Topic #89: new introduce roasts users accomplish mods se way welcome storage help reading don destroyed virtual avatar primary 75 case annual\n",
      "Topic #90: opinion bitter coffee based question community think broad bounty necessarily taste believe know pour press healthy arabica bad added hard\n",
      "Topic #91: awesome written moka nature disclaimer look shape goal matter sounds guys factors actually work en looking honest legitimate site members\n",
      "Topic #92: kopi question does luwak like taste coffee topic discouraged try works little black room usually chat alternative simply recipes way\n",
      "Topic #93: percolator hats consider let diamond view number sub welcome mods subject follows users flavors highly lot search allow menu haven\n",
      "Topic #94: coffee site refers obvious descaling activity true destroyed leave hats period point actually tag searching pure answered thing spam downvoted\n",
      "Topic #95: uses project difficult warrant removed editing flavored growing recommendations fits duplicate press obviously doubt known important chemistry deserves reference solved\n",
      "Topic #96: numbers does necessarily room discovered means mark automated helps zero useful quickly forums improve author multiple suggestion thread place votes\n",
      "Topic #97: questions question room based opinion coffee think seasoned chat use barista like advice policy ingredients merged make comment taste potentially\n",
      "Topic #98: similar caffeine away specifically stuff polls big guidance experiences fair dropdown suggestions favor flavored 24 research dozens little result discussions\n",
      "Topic #99: number feeds menu recommended moving ground sam okay improve beverage obviously makes does accomplished contributed way lists beta popular came\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf_vectorizer.transform(\n",
    "    [\"While answering a few of EdChum's questions I discovered that what I/we in the USA call pour over coffee is referred to as drip coffee in the UK. I added the pour-over tag to both questions I encountered but figured we should decide as a community which tag to use to describe this brewing process and then properly document it because drip-coffee means something different in the US (which is apparently referred to as filter-cofee in the UK). For clarification the method in question is shown in the image below. \",\n",
    "    \"Being newly created we have zero feeds appearing in our main chat right now. What blogs, news sites, or other important coffee related things should appear in our main chat room's feed? Post your suggestions/submissions.  \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist_unnormalized = np.matrix(lda.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist = doc_topic_dist_unnormalized/doc_topic_dist_unnormalized.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74]\n",
      " [74]]\n"
     ]
    }
   ],
   "source": [
    "print(doc_topic_dist.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9478947368420876"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_dist[1,74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
